* ICON symposium on distributional learning

  Organized by Katerina Chladkova.

** Topic

   My idea was that each speaker will present his/her model of distributional
   learning, show some human data, and discuss how their model addresses some
   language phenomena such as accent adaptation, or cross-language perception
   etc.  Another point to address could be what factors affect the success of
   learning, for instance the availability/necessity of lexical supervision,
   explicit feedback, acoustic saliency of the learned contrast. Any other ideas
   are also welcome.

   Each talk will be at least 30 minutes. The abstract should be max 300 words.
   Would you be able to send me yours by mid January?  Please let me know if you
   have any questions.

** Plan

   Need to make contrast with other people's theories.  Sounds like Joe will be
   there, but I'm not sure who else.  Big contrast is that it's *life long*, and
   *hierarchical*: in the ideal adapter, listeners are learning distribution not
   only of _sounds_, but of _talkers_ themselves.  I think communicating that
   insight would be useful.

   The other thing is to tie in with cognitive neuroscience.  Prediction error
   is the natural point of connection there.  Probabilistic inference ==
   minimize prediction error.

** Summary

   The ideal adapter is a computational-level framework for human speech
   perception (as well as domain-general perception), that starts with the
   observation that speech perception is a problem of _inference under
   uncertainty_: speech production is variable

   makes two important claims.
   First, it claims that distributional learning does not stop after a listener
   acquires their language, but continues throughout life.  Second, it claims
   that distributional learning is _hierarchical_, where listeners learn
   distributions of _sounds_ (phonetic categories, phonemes, words, etc.) _and_
   distributions of _talkers_ (or more specifically, talkers' accents, or the
   distributions of acoustic cues they produce for each linguistic unit).

   Both of these claims are derived from first principles, based on the nature
   of the problem that human speech poses to the perceptual system.


   # Needs something more about what this MEANS...
   The _ideal adapter_ is a computational-level theory of human speech perception.
   
   Even for a single talker, speech is highly variable: linguistic units
   (phonetic categories, words, etc.) are _distributions_ of acoustic cues.  This
   means that speech perception is a problem of inference under uncertainty.
   When the listener knows the distribution of cues that corresponds to each
   (phonetic) category, they can work backwards from a particular observed cue
   value to _infer_ which category was most likely.  As distributional learning
   theories of language acquisition have long acknowledged, these distributions
   must be _learned_ during acquisition.

   The ideal adapter, however, goes beyond these theories by placing
   distributional learning front and center in adult language processing.  This
   is because speech is variable not only _within_ a talker but also _between_
   talkers.  Thus, the cue distribution for each phonetic category (or other
   linguistic unit) changes from one situation to the next, and an "ideal
   adapter" needs to continuously update their beliefs about these cue
   distributions via distributional learning.  This is the first insight of the
   ideal adapter: because of talker variability, distributional learning should
   not stop after acquisition, but continue throughout life.  Indeed, listeners
   do rapidly adapt to unfamiliar talkers, and they do so in way that is
   quantitatively well predicted by a simple belief updating model based on the
   principles of the ideal adapter.

   The second insight of the ideal adapter is that this distributional learning
   is _hierarchical_.

   

   

   Talker variability means that distributional learning must 1) continue
   throuhgout life and 2) be _hierarchical_, in the sense that ...

   The central insight of the ideal adapter
   framework is that this distributional learning must continue throughout life,
   because talkers vary in the particular distributions they produce.  Moreover,
   using the formal tools of statistical inference, such distributional learning
   can be formalized as inference at a higher level: listeners must _infer_ cue
   distributions by combining information about which distributions are more or
   less compatible with the speech they are currently processing with their
   prior experience in other situations, which makes some distributions more or
   less likely /a priori/.

   - First point explains (in a quantitative way) rapid adaptation to an
     unfamiliar talker.
   - Second point explains how listeners balance stability and flexibility



   Recent computational work suggests that such
   distributional learning does not stop 
   
   

   and effective speech perception requires that listeners have
   reasonably good knowledge of what these distributions are.  Moreover, talkers
   themselves produce different distributions
   
   Speech perception as probabilistic inference.  Depends on knowing
   distributions of cues for each category.  Talker variability means that these
   distributions are different from one situation to the next.  So listeners
   need to continue to learn distributions _throughout life_.  Ideal adapter
   treats this distributional learning as probabilistic inference at another
   level: need to infer not only _what_ a talker is saying, but also _how_ they say
   things (the underlying distributions).  

   Critical insight is that listeners
   can use their previous experience to do this distributional learning much
   more efficiently than during acquisition.  If listeners learn the
   distribution of talker's accents, then they can use this knowledge as an
   informative prior about what kinds of cue distributions they are more or less
   likely to encounter.


   individual talkers are relatively
   consistent in their cue distributions, and so previous experience with a
   familiar talker is highly informative about the cue distributions they'll
   produce in the future.

   In this view, the speech perception system (and its neural implementations)
   attempts to minimize prediction error.

   
