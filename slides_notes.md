# Notes for slides

## WHere do I want to get with this?

Distributional learning isn't just for acquisition.  Happens throughout life, at
multiple levels.

In fact, the kind of world we inhabit _requires_ lifelong distributional
learning.

## Skeleton

Intro/motivation: perception in a noisy world, is inference under uncertainty.
Inference needs distributions.  When distributions change, need _contnuous
distributional learning_.


Now we have a puzzle: I've proposed that the same process that explains language
_acquisition_ explains _adaptation_ to talker variability.  But learning a
language is _really really hard_, and adapting to unfamiliar talkers is so easy
we only rarely notice that we're doing it.  What gives?

we can think of Distr. learning as a process of inference under uncertainty at
_another level_, or _hierarchical inference_.  two source of information: data
itself, and _prior expectations_. Where do these come from? Experience with
other talkers.

( talker's cue distributions -> point in cue space -> distribution of talkers ->
clusters of talkers; lots of clusters you _could_ learn, figuring out which
clusters are most informative is itself an inference process. make explicit
analogy: learn clusters of sounds so you can classify new sounds; learn clusters
of talkers so you can adapt to new talkers )

Evidence for this: rapid distributional learning is _constrained_ by range of
cue distributions in the language.

Why this matters: Something about prediction?  Integrating perception, learning,
and memory.

## Framing 

Not just lang/dist learning people.  SO need to go easy.  Get into it with
something like

* _Why_ is distributional learning important?  Why do we care about
  distributions?
    * Standard answer for speech: it's how you learn the structure of your
      language from unlabeled input.
    * Another reason: inference.  tradition of "ideal observer" models: when the
      signals from the world are _noisy_ and _ambiguous_, you need to know the
      distribution of signals generated by different possible states of the
      world.

Could even start off by _raising_ the question, then adjust standard slides to
answer that.  e.g. "here's the first reason that we should care about
distributions: if we know what the distributions of these cues are, we can work
backwards to _infer_ how likely each category is as an explanation of an
particular cue value we see".


## ALternative framing

Make it about prediction (more like Kavli) to better tie in with cog neuro
people.  We think the brain is a "prediction engine".  Inference as prediction
(and statistically optimal solution to a noisy, ambiguous world).  Making good
predictions requires knowing the distributions.  **That's** why distributions
matter (can raise this question to start, too: "you're all at this symposium
about distributional learning, but I want to start by questioning the entire
premise: **why** should we (or the brain) care about distributions at all?").

**OR**: we come back to prediction/neural stuff at the end.  "you might be
wondering what the connection to brain stuff is.  well...inference"


## Misc. things

As you're perceiving speech, you're making inferences at three levels: what the
talker is saying, how they say things (their own, particular cue distributions),
and _who_ they are (where they fit in the space of all talkers)




Connecting dist learning of categories in acquisition with dist learning of
socio-indexical groups: in order to extrapolate beyond _particular_ experiences,
you need to (explicitly or implicitly) infer some kind of category structure,
detect some clusters on top of the individual points.


One possible example here: what if you want to continue to track a particular
talker's distributions over multiple encounters?


## Empirical things to discuss

* Rapid recalibration: belief updating is a good description of a pretty
  low-level process.
* Dist learning/prior constraints: range of prior experience matters (-ish)
